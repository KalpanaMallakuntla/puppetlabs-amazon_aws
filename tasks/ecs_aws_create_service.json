{
	"description": "Runs and maintains a desired number of tasks from a specified task definition. If the number of tasks running in a service drops below desiredCount, Amazon ECS spawns another copy of the task in the specified cluster. To update an existing service, see UpdateService. In addition to maintaining the desired count of tasks in your service, you can optionally run your service behind a load balancer. The load balancer distributes traffic across the tasks that are associated with the service. For more information, see Service Load Balancing in the Amazon Elastic Container Service Developer Guide. You can optionally specify a deployment configuration for your service. During a deployment, the service scheduler uses the minimumHealthyPercent and maximumPercent parameters to determine the deployment strategy. The deployment is triggered by changing the task definition or the desired count of a service with an UpdateService operation. The minimumHealthyPercent represents a lower limit on the number of your service's tasks that must remain in the RUNNING state during a deployment, as a percentage of the desiredCount (rounded up to the nearest integer). This parameter enables you to deploy without using additional cluster capacity. For example, if your service has a desiredCount of four tasks and a minimumHealthyPercent of 50%, the scheduler can stop two existing tasks to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer are considered healthy if they are in the RUNNING state. Tasks for services that do use a load balancer are considered healthy if they are in the RUNNING state and the container instance they are hosted on is reported as healthy by the load balancer. The default value for a replica service for minimumHealthyPercent is 50% in the console and 100% for the AWS CLI, the AWS SDKs, and the APIs. The default value for a daemon service for minimumHealthyPercent is 0% for the AWS CLI, the AWS SDKs, and the APIs and 50% for the console. The maximumPercent parameter represents an upper limit on the number of your service's tasks that are allowed in the RUNNING or PENDING state during a deployment, as a percentage of the desiredCount (rounded down to the nearest integer). This parameter enables you to define the deployment batch size. For example, if your replica service has a desiredCount of four tasks and a maximumPercent value of 200%, the scheduler can start four new tasks before stopping the four older tasks (provided that the cluster resources required to do this are available). The default value for a replica service for maximumPercent is 200%. If you are using a daemon service type, the maximumPercent should remain at 100%, which is the default value. When the service scheduler launches new tasks, it determines task placement in your cluster using the following logic:   Determine which of the container instances in your cluster can support your service's task definition (for example, they have the required CPU, memory, ports, and container instance attributes).   By default, the service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a different placement strategy) with the placementStrategy parameter):   Sort the valid container instances, giving priority to instances that have the fewest number of running tasks for this service in their respective Availability Zone. For example, if zone A has one running service task and zones B and C each have zero, valid container instances in either zone B or C are considered optimal for placement.   Place the new service task on a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container instances with the fewest number of running tasks for this service.    ",
	"input_method": "stdin",
	"parameters":{
		
		
		
		
		    
			"placement_strategy":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"network_configuration":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"scheduling_strategy":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"cluster":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"launch_type":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"role":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"health_check_grace_period_seconds":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"client_token":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"load_balancers":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"placement_constraints":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"service_name":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"service_registries":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"platform_version":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"desired_count":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"task_definition":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"deployment_configuration":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			
	}
}