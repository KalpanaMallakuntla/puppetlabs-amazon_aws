{
	"description": " Starts asynchronous detection of explicit or suggestive adult content in a stored video. Amazon Rekognition Video can moderate content in a video stored in an Amazon S3 bucket. Use Video to specify the bucket name and the filename of the video. StartContentModeration returns a job identifier (JobId) which you use to get the results of the analysis. When content moderation analysis is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic that you specify in NotificationChannel. To get the results of the content moderation analysis, first check that the status value published to the Amazon SNS topic is SUCCEEDED. If so, call and pass the job identifier (JobId) from the initial call to StartContentModeration.  For more information, see Detecting Unsafe Content in the Amazon Rekognition Developer Guide.",
	"input_method": "stdin",
	"parameters":{
		
		
		
		
		    
			"job_tag":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"min_confidence":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"notification_channel":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"video":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			,
		    
			"client_request_token":{
			   "description": "",
			   "type": "Optional[String[1]]"
			}
			
	}
}